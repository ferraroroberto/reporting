# Social Media Automation Suite

A comprehensive Python-based automation system for collecting, processing, and analyzing social media data across multiple platforms. This suite integrates with various APIs to fetch social media metrics, processes the data, stores it in a PostgreSQL database (Supabase), and syncs with Notion for reporting and analysis.

## ğŸš€ Overview

This automation suite consists of three main modules that work together to create a complete social media analytics pipeline:

1. **Social Client** - Fetches data from social media platform APIs
2. **Process** - Transforms and uploads data to PostgreSQL/Supabase
3. **Notion** - Syncs data with Notion databases for reporting

## ğŸ“Š Supported Platforms

- LinkedIn (Profile & Posts)
- Instagram (Profile & Posts)
- Twitter/X (Profile & Posts)
- Threads (Profile & Posts)
- Substack (Profile & Posts)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Social APIs    â”‚â”€â”€â”€â”€â–¶â”‚ Data Processing â”‚â”€â”€â”€â”€â–¶â”‚    Supabase     â”‚
â”‚   (RapidAPI)    â”‚     â”‚   & Transform   â”‚     â”‚   PostgreSQL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
                                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                 â”‚     Notion      â”‚
                                                 â”‚   Databases     â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
automation/
â”œâ”€â”€ reporting/
â”‚   â”œâ”€â”€ social_client/         # API data collection
â”‚   â”‚   â”œâ”€â”€ social_api_client.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ process/               # Data processing & database operations
â”‚   â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”‚   â”œâ”€â”€ supabase_uploader.py
â”‚   â”‚   â”œâ”€â”€ profile_aggregator.py
â”‚   â”‚   â”œâ”€â”€ posts_consolidator.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ notion/                # Notion integration
â”‚   â”‚   â”œâ”€â”€ notion_update.py
â”‚   â”‚   â”œâ”€â”€ notion_supabase_sync.py
â”‚   â”‚   â”œâ”€â”€ notion_database_structure.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ config/                # Configuration files
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ mapping.json
â”‚   â”‚   â”œâ”€â”€ logger_config.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ results/               # Output directories
â”‚       â”œâ”€â”€ raw/               # Raw API responses
â”‚       â””â”€â”€ processed/         # Processed data files
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.7+
- PostgreSQL database (local or Supabase cloud)
- API keys for social media platforms (via RapidAPI)
- Notion API token (for Notion integration)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd automation/reporting
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   # Copy example configurations
   cp config/config_example.json config/config.json
   cp process/.env_example process/.env
   
   # Edit config files with your credentials
   ```

4. **Set up database**
   - Create a Supabase project or set up local PostgreSQL
   - Update database credentials in `.env` file

### Basic Usage

1. **Collect social media data**
   ```bash
   cd social_client
   python social_api_client.py
   ```

2. **Process and upload data**
   ```bash
   cd ../process
   python data_processor.py
   ```

3. **Aggregate profiles and posts**
   ```bash
   python profile_aggregator.py
   python posts_consolidator.py
   ```

4. **Sync with Notion (optional)**
   ```bash
   cd ../notion
   python notion_update.py YYYYMMDD
   ```

## ğŸ“‹ Module Documentation

### [Social Client Module](reporting/social_client/README.md)

Fetches data from social media APIs:
- Automatic timestamp-based file naming
- Skip existing data to avoid duplicate API calls
- Debug mode for troubleshooting
- Progress tracking and comprehensive logging

**Key Features:**
- ğŸš€ Multi-platform support
- ğŸ’¾ JSON output with metadata
- ğŸ”„ Smart caching
- ğŸ Debug mode

### [Process Module](reporting/process/README.md)

Handles data transformation and database operations:
- Field mapping based on configuration
- Automatic type conversion
- Database table creation
- Batch processing for large datasets

**Key Components:**
- ğŸ“Š `data_processor.py` - Main processing engine
- ğŸ“¤ `supabase_uploader.py` - Database interface
- ğŸ”„ `profile_aggregator.py` - Consolidates follower counts
- ğŸ“ `posts_consolidator.py` - Merges posts data

### [Notion Module](reporting/notion/README.md)

Integrates with Notion for reporting:
- Bidirectional sync with Supabase
- Automatic schema detection
- Change tracking and logging
- Support for all Notion property types

**Key Tools:**
- ğŸ“ `notion_update.py` - Updates Notion with Supabase data
- ğŸ”„ `notion_supabase_sync.py` - Continuous database sync
- ğŸ“Š `notion_database_structure.py` - Schema analysis

### [Configuration](reporting/config/README.md)

Central configuration management:
- API credentials and endpoints
- Field mapping rules
- Database settings
- Logging configuration

## ğŸ”„ Typical Workflow

### Daily Data Collection

```bash
# 1. Fetch latest social media data
cd reporting/social_client
python social_api_client.py

# 2. Process and upload to database
cd ../process
python data_processor.py

# 3. Aggregate data
python profile_aggregator.py
python posts_consolidator.py

# 4. Update Notion (if needed)
cd ../notion
python notion_update.py $(date +%Y%m%d)
```

### Continuous Notion Sync

```bash
# Run continuous sync in background
cd reporting/notion
python notion_supabase_sync.py
```

## ğŸ“Š Data Schema

### Profile Data
- `date`: Collection date
- `platform`: Social media platform
- `num_followers_*`: Follower count per platform

### Posts Data
- `date`: Collection date
- `platform`: Source platform
- `post_id`: Unique identifier
- `posted_at`: Publication timestamp
- `is_video`: Video content flag
- `num_likes`: Engagement metrics
- `num_comments`: Comment count
- `num_reshares`: Share/repost count

## ğŸ”§ Advanced Configuration

### Debug Mode

Most scripts support debug mode for detailed logging:
```bash
python script_name.py --debug
```

### Environment-Specific Settings

Switch between local and cloud databases:
```bash
python supabase_uploader.py --environment local
```

### Custom Configurations

Override default configuration files:
```bash
python notion_supabase_sync.py --config custom_config.json
```

## ğŸ› Troubleshooting

### Common Issues

1. **API Rate Limits**
   - Use `--skip-existing` flag to avoid re-fetching data
   - Implement delays between API calls

2. **Database Connection Errors**
   - Verify credentials in `.env` file
   - Check network connectivity
   - Ensure database is accessible

3. **Missing Data Fields**
   - Review `mapping.json` for correct field paths
   - Enable debug mode to see raw API responses
   - Check if API response structure changed

4. **Notion Sync Issues**
   - Verify Notion API token is valid
   - Check database IDs in configuration
   - Review Notion API rate limits

### Debug Commands

```bash
# Test database connection
cd reporting/process
python supabase_test_connect.py

# Analyze Notion database structure
cd ../notion
python notion_database_structure.py --debug

# Process single platform
cd ../social_client
python social_api_client.py --platform linkedin_profile --debug
```

## ğŸ“ˆ Performance Optimization

- **Batch Processing**: Data is processed in batches to handle large datasets
- **Incremental Sync**: Only new/modified data is synced to avoid redundant operations
- **Connection Pooling**: Database connections are pooled for efficiency
- **Smart Caching**: API responses are cached daily to minimize API calls

## ğŸ” Security Best Practices

1. **Never commit sensitive data**
   - Keep `config.json` out of version control
   - Use `.env` files for database credentials
   - Rotate API keys regularly

2. **Use environment variables in production**
   ```bash
   export SUPABASE_URL="your-url"
   export SUPABASE_KEY="your-key"
   ```

3. **Implement access controls**
   - Use read-only database users where possible
   - Limit API key permissions
   - Enable Supabase Row Level Security (RLS)

## ğŸš§ Development

### Adding New Platforms

1. **Update configuration**
   - Add platform config to `config.json`
   - Define field mappings in `mapping.json`

2. **Test data collection**
   ```bash
   python social_api_client.py --platform new_platform --debug
   ```

3. **Verify processing**
   ```bash
   python data_processor.py --debug
   ```

### Extending Functionality

- Create custom processors in the `process` module
- Add new Notion property type handlers
- Implement additional aggregation queries

## ğŸ“ License and contact

This project is free software for personal use from Roberto Ferraro ğŸ˜‡

https://www.linkedin.com/in/ferraroroberto/

Built with â¤ï¸ for automated social media analytics and reporting
